# Laboratorio: Instalaci√≥n de un Cl√∫ster de Kubernetes con Kubeadm y Despliegue de una Aplicaci√≥n

## Tabla de Contenidos
1. [Introducci√≥n](/images/#introducci√≥n)
2. [Arquitectura de la Soluci√≥n](/images/#arquitectura-de-la-soluci√≥n)
3. [Preparaci√≥n del Entorno](/images/#preparaci√≥n-del-entorno)
4. [Instalaci√≥n y Configuraci√≥n del Cl√∫ster](/images/#instalaci√≥n-y-configuraci√≥n-del-cl√∫ster)
5. [Despliegue de la Aplicaci√≥n](/images/#despliegue-de-la-aplicaci√≥n)
6. [Dificultades Encontradas y Soluciones](/images/#dificultades-encontradas-y-soluciones)
7. [Verificaci√≥n y Pruebas](/images/#verificaci√≥n-y-pruebas)
8. [Conclusiones](/images/#conclusiones)
9. [Anexos](/images/#anexos)

## Introducci√≥n

El presente informe documenta la implementaci√≥n de un cl√∫ster de Kubernetes utilizando kubeadm sobre una distribuci√≥n Ubuntu 24.04, as√≠ como el despliegue de una aplicaci√≥n web containerizada. El proyecto se desarroll√≥ siguiendo los lineamientos establecidos en el laboratorio de Infraestructura 3, con el objetivo de demostrar competencias en la administraci√≥n de contenedores y orquestaci√≥n de servicios.

La soluci√≥n implementada automatiza completamente el proceso de instalaci√≥n, configuraci√≥n y despliegue mediante scripts de aprovisionamiento, garantizando la reproducibilidad y escalabilidad del entorno de desarrollo.

## Arquitectura de la Soluci√≥n

### Componentes del Sistema

La implementaci√≥n se bas√≥ en una arquitectura de cl√∫ster distribuido compuesta por:

- **Nodo Master (k8s-master)**: 192.168.56.10
  - 2 GB RAM, 2 CPUs
  - Funciones: API Server, etcd, Scheduler, Controller Manager
- **Nodos Worker**: 
  - k8s-worker1: 192.168.56.11 (1.5 GB RAM, 1 CPU)
  - k8s-worker2: 192.168.56.12 (1.5 GB RAM, 1 CPU)
- **Aplicaci√≥n**: Web Flask containerizada expuesta mediante NodePort

> ![Cluster Architecture](/images/k8s_cluster_architecture.svg)

### Red de Contenedores

Se implement√≥ Flannel como CNI (Container Network Interface) con las siguientes especificaciones:
- Red de pods: `10.244.0.0/16`
- Protocolo: VXLAN sobre interfaz `eth1`
- Configuraci√≥n optimizada para VirtualBox

## Preparaci√≥n del Entorno

### Estructura del Proyecto

```
‚îú‚îÄ‚îÄ Vagrantfile                    # Configuraci√≥n de m√°quinas virtuales
‚îú‚îÄ‚îÄ master_script.sh              # Script maestro de automatizaci√≥n
‚îú‚îÄ‚îÄ .env.example                  # Plantilla de configuraci√≥n
‚îú‚îÄ‚îÄ provisioning/
‚îÇ   ‚îú‚îÄ‚îÄ common.sh                 # Configuraci√≥n com√∫n de nodos
‚îÇ   ‚îú‚îÄ‚îÄ master.sh                 # Configuraci√≥n espec√≠fica del master
‚îÇ   ‚îî‚îÄ‚îÄ worker.sh                 # Configuraci√≥n espec√≠fica de workers
‚îú‚îÄ‚îÄ K8S_files/                    # Manifiestos de Kubernetes
‚îú‚îÄ‚îÄ scripts/                      # Scripts de despliegue
‚îú‚îÄ‚îÄ app.py                        # Aplicaci√≥n Flask
‚îî‚îÄ‚îÄ Dockerfile                    # Imagen de contenedor
```

### Configuraci√≥n Inicial

Antes de ejecutar el laboratorio, se configur√≥ el archivo [`.env`](.env.example) con las credenciales necesarias:

```bash
# Copy this file and rename it to .env, then edit the values

# ===== DOCKER HUB CONFIGURATION =====
DOCKER_USERNAME=tu_usuario_dockerhub
DOCKER_PASSWORD=tu_password_dockerhub  
DOCKER_EMAIL=tu_email@ejemplo.com

# ===== APPLICATION CONFIGURATION =====
APP_NAME=webapp
APP_VERSION=v1
APP_REPOSITORY_URL=https://github.com/mariocr73/K8S-apps.git

# ===== DATABASE CONFIGURATION (for secrets) =====
DB_USERNAME=admin
DB_PASSWORD=password123

# ===== CLUSTER CONFIGURATION =====
MASTER_IP=192.168.56.10
WORKER1_IP=192.168.56.11  
WORKER2_IP=192.168.56.12
SERVICE_NODE_PORT=30001

# ===== ADVANCED CONFIGURATION =====
# Pod wait timeout (seconds)
POD_TIMEOUT=300
# Application namespace (optional, default is 'default')
APP_NAMESPACE=default
```

## Instalaci√≥n y Configuraci√≥n del Cl√∫ster

### Ejecuci√≥n del Script Maestro

El proceso de instalaci√≥n se automatiz√≥ completamente mediante el script `master_script.sh`, el cual orquesta los siguientes pasos:

```bash
./master_script.sh
```

> ![Master Script Result](/images/master_script_result.png)

### Configuraci√≥n Com√∫n de Nodos (`common.sh`)

El script `common.sh` se ejecuta en todos los nodos y realiza la instalaci√≥n y configuraci√≥n de todos los componentes base necesarios para el funcionamiento del cl√∫ster Kubernetes. Esta configuraci√≥n es fundamental y debe aplicarse de manera id√©ntica en todos los nodos para garantizar la consistencia del entorno.

#### Actualizaci√≥n del Sistema Base
```bash
export DEBIAN_FRONTEND=noninteractive
apt-get update
apt-get upgrade -y
```

**Justificaci√≥n**: Se actualiza el sistema para asegurar que todos los paquetes est√©n en sus versiones m√°s recientes y securizadas, estableciendo un punto de partida com√∫n para todos los nodos.

#### Deshabilitaci√≥n Completa del Swap
```bash
# Deshabilitaci√≥n permanente del swap
swapoff -a
sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab
rm -f /swap.img
systemctl stop systemd-swap 2>/dev/null || true
systemctl disable systemd-swap 2>/dev/null || true
```

**Justificaci√≥n**: Kubernetes requiere obligatoriamente que el swap est√© deshabilitado para funcionar correctamente. El kubelet falla al iniciar si detecta swap activo, ya que puede interferir con la gesti√≥n de recursos y el aislamiento de contenedores. Se implementa una deshabilitaci√≥n exhaustiva que incluye:
- Desactivaci√≥n inmediata (`swapoff -a`)
- Eliminaci√≥n de entradas en fstab para persistencia
- Eliminaci√≥n f√≠sica de archivos de swap
- Deshabilitaci√≥n de servicios systemd relacionados

> ![Swap Disabled On Master Node](/images/swap_disabled_on_master_node.png)

#### Configuraci√≥n de M√≥dulos del Kernel
```bash
cat <<EOF | tee /etc/modules-load.d/k8s.conf
overlay
br_netfilter
EOF

modprobe overlay
modprobe br_netfilter
```

**Justificaci√≥n**: 
- **overlay**: Necesario para el sistema de archivos de contenedores, permite la superposici√≥n de capas de imagen
- **br_netfilter**: Esencial para el filtrado de paquetes en bridges de red, requerido para que iptables funcione correctamente con el tr√°fico de red de Kubernetes

#### Par√°metros de Red del Sistema (sysctl)
```bash
cat <<EOF | tee /etc/sysctl.d/k8s.conf
# Requisitos core de Kubernetes
net.bridge.bridge-nf-call-iptables  = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward                 = 1

# Optimizaciones para VirtualBox
net.ipv4.conf.all.forwarding        = 1
net.ipv4.conf.all.rp_filter         = 0
net.ipv4.conf.default.rp_filter     = 0
net.ipv4.conf.eth0.rp_filter        = 0
net.ipv4.conf.eth1.rp_filter        = 0

# Optimizaciones de connection tracking
net.netfilter.nf_conntrack_max       = 1000000
net.netfilter.nf_conntrack_tcp_timeout_established = 86400

# L√≠mites de memoria y descriptores de archivo
fs.inotify.max_user_instances        = 8192
fs.inotify.max_user_watches          = 1048576
fs.file-max                          = 2097152
EOF
```

**Justificaci√≥n**: 
- **Bridge netfilter**: Permite a iptables procesar tr√°fico de red bridgeado, fundamental para kube-proxy
- **IP forwarding**: Habilita el reenv√≠o de paquetes entre interfaces, necesario para la comunicaci√≥n entre pods
- **RP filter deshabilitado**: En VirtualBox, el reverse path filtering puede bloquear tr√°fico leg√≠timo entre nodos
- **Connection tracking**: Aumenta los l√≠mites para manejar m√∫ltiples conexiones simult√°neas
- **File limits**: Incrementa los l√≠mites para el monitoreo de archivos (inotify) usado por kubelet

#### Configuraci√≥n Exhaustiva del Firewall
```bash
# Instalaci√≥n y configuraci√≥n de UFW
apt-get install -y ufw
ufw --force reset
ufw --force enable

# Acceso esencial
ufw allow ssh
ufw allow from 10.0.2.0/24         # Red NAT de VirtualBox
ufw allow from 192.168.56.0/24     # Red host-only de VirtualBox

# Redes de Kubernetes
ufw allow from 10.244.0.0/16       # Red de pods (Flannel)
ufw allow from 10.96.0.0/12        # Red de servicios

# Puertos del plano de control
ufw allow 6443/tcp                  # API server
ufw allow 2379:2380/tcp             # etcd server client API
ufw allow 10250/tcp                 # Kubelet API
ufw allow 10251/tcp                 # kube-scheduler
ufw allow 10252/tcp                 # kube-controller-manager
ufw allow 10256/tcp                 # kube-proxy health check

# Puertos de Flannel
ufw allow 8472/udp                  # Flannel VXLAN
ufw allow 8285/udp                  # Flannel host-gw
ufw allow 51820/udp                 # Flannel wireguard

# Rango de NodePort
ufw allow 30000:32767/tcp           # Servicios NodePort
ufw allow 30000:32767/udp           # Servicios NodePort UDP

# Permitir todo el tr√°fico en la interfaz privada
ufw allow in on eth1 to any
ufw allow out on eth1 to any
```

**Justificaci√≥n**: Kubernetes requiere comunicaci√≥n entre m√∫ltiples puertos y protocolos. Se configura UFW de manera permisiva pero controlada para:
- Mantener acceso SSH para administraci√≥n
- Permitir comunicaci√≥n en redes privadas de VirtualBox
- Abrir puertos espec√≠ficos de componentes de Kubernetes
- Habilitar comunicaci√≥n de Flannel (VXLAN sobre UDP)
- Permitir el rango completo de NodePorts para servicios

#### Instalaci√≥n de Dependencias del Sistema
```bash
apt-get install -y \
    apt-transport-https \
    ca-certificates \
    curl \
    gnupg \
    lsb-release \
    vim \
    git \
    wget \
    net-tools \
    htop \
    iptables \
    socat \
    conntrack \
    ipset
```

**Justificaci√≥n de cada paquete**:
- **apt-transport-https**: Permite descargar paquetes desde repositorios HTTPS
- **ca-certificates**: Certificados de autoridades certificadoras para conexiones seguras
- **curl, wget**: Herramientas de descarga para scripts y archivos
- **gnupg**: Manejo de claves GPG para verificaci√≥n de repositorios
- **git**: Control de versiones para clonaci√≥n de repositorios
- **vim**: Editor de texto avanzado para configuraciones
- **net-tools**: Herramientas de red (ifconfig, netstat) para diagn√≥stico
- **htop**: Monitor de procesos mejorado para troubleshooting
- **iptables**: Gesti√≥n de reglas de firewall, usado por kube-proxy
- **socat**: Relay de sockets, usado por kubectl port-forward
- **conntrack**: Herramientas de connection tracking para diagn√≥stico de red
- **ipset**: Gesti√≥n eficiente de conjuntos de IPs para iptables

#### Instalaci√≥n y Configuraci√≥n de Containerd
```bash
# Instalaci√≥n de versi√≥n espec√≠fica
apt-get install -y containerd.io=1.6.*
apt-mark hold containerd.io

# Configuraci√≥n para Kubernetes
mkdir -p /etc/containerd
containerd config default | tee /etc/containerd/config.toml

# Habilitaci√≥n de SystemdCgroup
sed -i 's/SystemdCgroup = false/SystemdCgroup = true/g' /etc/containerd/config.toml

# Actualizaci√≥n de imagen sandbox
sed -i 's|sandbox_image = "registry.k8s.io/pause:.*"|sandbox_image = "registry.k8s.io/pause:3.9"|g' /etc/containerd/config.toml

# Activaci√≥n del servicio
systemctl restart containerd
systemctl enable containerd
```

**Justificaci√≥n**: 
- **Containerd**: Runtime de contenedores recomendado por Kubernetes, m√°s liviano que Docker
- **Versi√≥n espec√≠fica 1.6**: Garantiza compatibilidad y evita actualizaciones no deseadas
- **SystemdCgroup**: Mejora la integraci√≥n con systemd para gesti√≥n de recursos
- **Imagen sandbox actualizada**: Asegura compatibilidad con la versi√≥n de Kubernetes instalada

> ![Container status](/images/containerd_status.png)
#### Configuraci√≥n del Repositorio Kubernetes
```bash
# Limpieza de configuraciones previas
rm -f /etc/apt/keyrings/kubernetes-apt-keyring.gpg
rm -f /etc/apt/sources.list.d/kubernetes.list

# Agregado del repositorio oficial
curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.28/deb/Release.key | gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.28/deb/ /' | tee /etc/apt/sources.list.d/kubernetes.list
```

**Justificaci√≥n**: Se utiliza el repositorio oficial de Kubernetes para garantizar autenticidad y obtener versiones estables de las herramientas.

#### Instalaci√≥n de Herramientas Kubernetes
```bash
# Instalaci√≥n de versi√≥n espec√≠fica
KUBE_VERSION="1.28.2-1.1"
apt-get install -y \
    kubelet=$KUBE_VERSION \
    kubeadm=$KUBE_VERSION \
    kubectl=$KUBE_VERSION

# Prevenci√≥n de actualizaciones autom√°ticas
apt-mark hold kubelet kubeadm kubectl
```

**Justificaci√≥n**:
- **kubelet**: Agente que ejecuta en cada nodo, gestiona pods y contenedores
- **kubeadm**: Herramienta de bootstrapping para crear cl√∫steres
- **kubectl**: Cliente de l√≠nea de comandos para interactuar con el API server
- **Versi√≥n espec√≠fica**: Garantiza compatibilidad entre todos los componentes
- **Hold de paquetes**: Evita actualizaciones autom√°ticas que podr√≠an romper el cl√∫ster

#### Configuraci√≥n del Entorno kubectl
```bash
# Autocompletado y aliases para el usuario vagrant
echo 'source <(kubectl completion bash)' >> /home/vagrant/.bashrc
echo 'alias k=kubectl' >> /home/vagrant/.bashrc
echo 'complete -o default -F __start_kubectl k' >> /home/vagrant/.bashrc
```

**Justificaci√≥n**: Mejora la experiencia de usuario proporcionando autocompletado de comandos y aliases para mayor productividad en la administraci√≥n del cl√∫ster.

#### Configuraci√≥n de Systemd para Kubelet
```bash
mkdir -p /etc/systemd/system/kubelet.service.d
cat <<EOF | tee /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
[Service]
Environment="KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf"
Environment="KUBELET_CONFIG_ARGS=--config=/var/lib/kubelet/config.yaml"
EnvironmentFile=-/var/lib/kubelet/kubeadm-flags.env
EnvironmentFile=-/etc/default/kubelet
ExecStart=
ExecStart=/usr/bin/kubelet \$KUBELET_KUBECONFIG_ARGS \$KUBELET_CONFIG_ARGS \$KUBELET_KUBEADM_ARGS \$KUBELET_EXTRA_ARGS
EOF

systemctl daemon-reload
```

**Justificaci√≥n**: Esta configuraci√≥n permite que kubeadm gestione din√°micamente la configuraci√≥n del kubelet, incluyendo par√°metros espec√≠ficos del nodo y configuraciones de bootstrap.

### Configuraci√≥n del Nodo Master (`master.sh`)

#### Inicializaci√≥n del Cl√∫ster

```bash
kubeadm init \
    --pod-network-cidr=10.244.0.0/16 \
    --apiserver-advertise-address=$MASTER_IP \
    --control-plane-endpoint=$MASTER_IP \
    --upload-certs \
    --ignore-preflight-errors=NumCPU
```

> ![Kube Init Result](/images/kube_init_result.png)

#### Configuraci√≥n de kubectl
```bash
mkdir -p /home/vagrant/.kube
cp -f /etc/kubernetes/admin.conf /home/vagrant/.kube/config
chown vagrant:vagrant /home/vagrant/.kube/config
```

#### Instalaci√≥n de Flannel Optimizada

Una de las principales dificultades enfrentadas fue la configuraci√≥n de la red de contenedores. Se desarroll√≥ una configuraci√≥n personalizada de Flannel espec√≠ficamente optimizada para VirtualBox:

```yaml
# Configuraci√≥n cr√≠tica en el DaemonSet de Flannel
containers:
- name: kube-flannel
  image: docker.io/flannel/flannel:v0.24.2
  command:
  - /opt/bin/flanneld
  args:
  - --ip-masq
  - --kube-subnet-mgr
  - --iface=eth1          # Interfaz espec√≠fica para VirtualBox
  - --iface-regex=eth1
```

> ![Flannel Pods Running](/images/flannel_pods_running.png)

### Configuraci√≥n de Nodos Worker (`worker.sh`)

#### Verificaci√≥n de Conectividad
Antes de unirse al cl√∫ster, cada worker verifica la conectividad con el master:

```bash
# Verificaci√≥n de conectividad con el API server
if ! timeout 10 bash -c "</dev/tcp/$MASTER_IP/6443" 2>/dev/null; then
    echo "‚ùå FATAL: Cannot connect to API server port 6443 on master"
    exit 1
fi
```

#### Ejecuci√≥n del Join Command
```bash
# Ejecuci√≥n del comando de uni√≥n con reintentos
for attempt in {1..10}; do
    if timeout 300 bash /vagrant/join-command.sh; then
        JOIN_SUCCESS=true
        break
    fi
done
```

> ![All Nodes In Cluster](/images/all_nodes_in_cluster.png)

## Despliegue de la Aplicaci√≥n

### Construcci√≥n de la Imagen Docker

#### Aplicaci√≥n Flask
La aplicaci√≥n desarrollada es un servidor web simple en Flask:

```python
from flask import Flask
app = Flask(__name__)

@app.route('/')
def hello_world():
    return '¬°Hola Mundo desde Kubernetes!'

if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0')
```

#### Dockerfile
```dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY . /app

RUN pip install Flask

CMD ["python", "app.py"]
```

> ![Docker Build](/images/docker_build.png)

> **Nota:** El build y el push de la aplicaci√≥n se realizaron desde la m√°quina host. Si se intentaba hacerlo desde alg√∫n nodo (ya fuera el master o un worker), surg√≠an problemas relacionados con la versi√≥n de *containerd* y la que incluye la instalaci√≥n de Docker. Para evitar riesgos que pudieran afectar el cl√∫ster, se prefiri√≥ hacerlo directamente desde la m√°quina host.

### Creaci√≥n de Secrets

Se implement√≥ la gesti√≥n segura de credenciales mediante Kubernetes Secrets:

```bash
# Secret para Docker Hub
kubectl create secret docker-registry regcred \
    --docker-server=https://index.docker.io/v1/ \
    --docker-username="$DOCKER_USERNAME" \
    --docker-password="$DOCKER_PASSWORD" \
    --docker-email="$DOCKER_EMAIL"

# Secret para base de datos
kubectl apply -f - <<EOF
apiVersion: v1
kind: Secret
metadata:
  name: db-secrets
type: Opaque
data:
  db_username: $(echo -n "$DB_USERNAME" | base64 -w 0)
  db_userpassword: $(echo -n "$DB_PASSWORD" | base64 -w 0)
EOF
```

> ![Secrets Config](/images/secrets_config.png)

### Manifiestos de Kubernetes

#### Deployment
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webapp-deployment
spec:
  replicas: 2
  selector:
    matchLabels:
      app: hola-mundo
  template:
    metadata:
      labels:
        app: hola-mundo
    spec:
      containers:
      - name: app-container
        image: <nombre_de_usuario_en_docker_hub>/<nombre_del_repositorio>:<tag>
        ports:
        - containerPort: 5000
      imagePullSecrets:
      - name: regcred
```

#### Service
```yaml
apiVersion: v1
kind: Service
metadata:
  name: webapp-service
spec:
  selector:
    app: hola-mundo
  ports:
    - protocol: TCP
      port: 80
      targetPort: 5000
      nodePort: 30001
  type: NodePort
```

> ![Verification of Manifests](/images/verification_of_manifests.png)

## Dificultades Encontradas y Soluciones

### 1. Configuraci√≥n de Red en VirtualBox

**Problema**: La configuraci√≥n est√°ndar de Flannel no funcionaba correctamente en el entorno VirtualBox, causando problemas de conectividad entre pods.

**Soluci√≥n**: Se desarroll√≥ una configuraci√≥n personalizada de Flannel especificando la interfaz de red `eth1` (red host-only de VirtualBox) mediante los par√°metros:
```bash
--iface=eth1
--iface-regex=eth1
```

### 2. Gesti√≥n del Swap

**Problema**: Kubernetes requiere que el swap est√© completamente deshabilitado, pero las configuraciones est√°ndar no siempre son efectivas.

**Soluci√≥n**: Se implement√≥ una deshabilitaci√≥n exhaustiva:
- Desactivaci√≥n inmediata con `swapoff -a`
- Comentado de entradas en `/etc/fstab`
- Eliminaci√≥n f√≠sica del archivo de swap
- Verificaci√≥n con comprobaciones de estado

### 3. Configuraci√≥n del Firewall

**Problema**: Las reglas de firewall predeterminadas bloqueaban la comunicaci√≥n entre componentes del cl√∫ster.

**Soluci√≥n**: Se desarroll√≥ una configuraci√≥n espec√≠fica de UFW que permite:
- Tr√°fico en redes privadas de VirtualBox
- Puertos espec√≠ficos de Kubernetes
- Comunicaci√≥n de Flannel VXLAN
- Rango completo de NodePorts

### 4. Sincronizaci√≥n de Nodos Worker

**Problema**: Los nodos worker intentaban unirse antes de que el master estuviera completamente inicializado.

**Soluci√≥n**: Se implement√≥ un sistema de verificaci√≥n con:
- Comprobaciones de conectividad de red
- Verificaci√≥n del estado del API server
- Reintentos con backoff exponencial
- Timeouts configurables

> ![Worker Joined to Cluster](/images/worker_joined_to_cluster.png)

## Verificaci√≥n y Pruebas

### Estado del Cl√∫ster

> ![Cluster Verification](/images/verification.png)

### Aplicaci√≥n Desplegada

> ![Pods Running](/images/pods_running.png)

### Pruebas de Conectividad

El script maestro incluye verificaciones autom√°ticas de conectividad:

```bash
# Test de conectividad a la aplicaci√≥n
for IP in "$MASTER_IP" "$WORKER1_IP" "$WORKER2_IP"; do
    if curl -s --connect-timeout 10 "http://$IP:$ACTUAL_NODE_PORT" | grep -q "Hola"; then
        print_success "Application responds at http://$IP:$ACTUAL_NODE_PORT"
        TEST_SUCCESS=true
        break
    fi
done
```

> ![App Operation](/images/app_operation.png)

> ![Curl Working](/images/curl_working.png)

### Escalado de la Aplicaci√≥n

Se realizaron pruebas de escalado para verificar la funcionalidad del cl√∫ster:

```bash
kubectl scale deployment webapp-deployment --replicas=5
```

> ![Successful Scaling](/images/successful_scaling.png)

## Conclusiones

### Logros Alcanzados

1. **Implementaci√≥n Exitosa**: Se logr√≥ la instalaci√≥n completa de un cl√∫ster Kubernetes funcional con kubeadm sobre Ubuntu 24.04.

2. **Automatizaci√≥n Completa**: Se desarroll√≥ un sistema de scripts que automatiza todo el proceso, desde la creaci√≥n de VMs hasta el despliegue de aplicaciones.

3. **Optimizaci√≥n para VirtualBox**: Se resolvieron las dificultades espec√≠ficas del entorno virtualizado mediante configuraciones personalizadas.

4. **Despliegue de Aplicaci√≥n**: Se implement√≥ exitosamente una aplicaci√≥n web containerizada con exposici√≥n mediante NodePort.

5. **Gesti√≥n de Secrets**: Se implement√≥ la gesti√≥n segura de credenciales utilizando las mejores pr√°cticas de Kubernetes.

### Aprendizajes T√©cnicos

- **Configuraci√≥n de Red**: La importancia de la configuraci√≥n correcta de CNI en entornos virtualizados.
- **Gesti√≥n de Firewall**: La necesidad de configuraciones espec√≠ficas de firewall para Kubernetes.
- **Automatizaci√≥n**: El valor de los scripts de aprovisionamiento para entornos reproducibles.
- **Troubleshooting**: T√©cnicas de diagn√≥stico para problemas de conectividad en cl√∫steres.

### Valor Acad√©mico

Este laboratorio demuestra competencias en:
- Administraci√≥n de sistemas Linux
- Containerizaci√≥n con Docker
- Orquestaci√≥n con Kubernetes
- Automatizaci√≥n de infraestructura
- Resoluci√≥n de problemas t√©cnicos complejos

## Anexos

### Anexo A: Comandos de Verificaci√≥n

```bash
# Verificar estado del cl√∫ster
kubectl cluster-info
kubectl get nodes -o wide
kubectl get pods --all-namespaces

# Verificar aplicaci√≥n
kubectl get deployments
kubectl get services
kubectl logs -l app=hola-mundo

# Verificar red
kubectl get pods -n kube-flannel
ip route show | grep 10.244
```

### Anexo B: URLs de Acceso

- Master: http://192.168.56.10:30001
- Worker1: http://192.168.56.11:30001  
- Worker2: http://192.168.56.12:30001

### Anexo C: Estructura de Archivos Cr√≠ticos

- **Vagrantfile**: Configuraci√≥n de VMs con especificaciones de hardware y red
- **master_script.sh**: Orquestador principal del laboratorio
- **provisioning/**: Scripts de configuraci√≥n automatizada de nodos
- **scripts/**: Herramientas de gesti√≥n de im√°genes y despliegue

---

> **Nota**: Para desmontar todo, basta con ejecutar:
> ```
> vagrant destroy
> ```
> ¬°Y listo! üôÇ
